---
layout: page
title: Data Science Project Experience
---

In the following, I provide an overview of the projects related to machine learning (ml). They will be subdivided into three major groups, which are the ml-projects I carried out as [data science professional](#data-science-professional-ml-projects), the ml-projects I carried out as an [academic researcher](#academic-research-ml-projects) and the ml-projects I carried out due to [personal interests](#personal-interest-ml-projects).


&nbsp;

## **Data Science Professional ML-Projects**

| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| ----------- | ----------- | ----------- | ----------- |
| **Disease Detection** ![brain_volumetry](images/projects/brain_volumetry.png) | **To identity pathological cerebral changes** | *I developed explainable classification ml-models providing disease propensity scores based on labeled MRI volumetry datasets. In addition, I documented relevant scientific publications on this topic.* | **Magnetic Resonance Imaging, Image Analysis, Machine Learning, Data Preparation, Data Visualization, Explainable AI (shapley values), Python (numpy, pandas, sklearn, matplotlib, shap), Jupyter, Colab, VSCode, Gitlab** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Purchase Analysis** ![maverick_buying](images/projects/maverick_buying.png)| **To identity incorrect order processes** | *I developed a classification model from historical tabular data providing propensity scores for incorrect orders. I deployed and updated the model in SPSS modeler. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Data Preparation, Data Visualization, Natural Language Processing (bag-of-words), Python (numpy, pandas, sklearn, matplotlib), R, Jupyter, RStudio, Spyder, SPSS Modeler** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Predictive Maintenance** ![pred_maintenance](images/projects/pred_maintenance.png)| **To predict machine-failure of wind turbines** | *I developed a classification model based on weather and sensory time-series data providing propensity scores for imminent failure of wind turbines. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Data Preparation, Data Visualization, SPSS Modeler** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Credit Default Prediction** ![creditworthyness](images/projects/creditworthyness.png)| **To predict upcoming payment defaults** | *I developed a classification model based on tabular time-series data providing the propensity scores of upcoming payment defaults. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Deep Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn, keras), Jupyter, VSCode** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Data Deduplication** ![entity_res](images/projects/entity_res.png)| **To remove duplicated rows from large datasets** | *I developed a classification-clustering mixture model based on tabular data to detect duplicates of names and addresses. In addition, I supported the development team with building data-pipelines and the deployment of the model.* | **Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn, dedupe), Jupyter, VSCode, git, SQL** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Customer Value** ![customer_value](images/projects/customer_value.png)| **To improve the customer value model** | *I consulted the specialist department on how to improve an existing customer value model applying state-of-the-art machine learning methods. I further supported the data engineering team to continuously deploy new model versions.* | **Machine Learning, Data Preparation, Data Visualization, SPSS Modeler** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Customer Churn** ![churn](images/projects/churn.png)| **To improve the customer churn model** | *I consulted the specialist department on how to improve the existing customer churn model applying state-of-the-art machine learning methods. I further supported the data engineering team to continuously deploy new model versions.* | **Machine Learning, Data Preparation, Data Visualization, SPSS Modeler** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Customer Segmentation** ![customer_segmentation](images/projects/customer_segmentation.png)| **To develop customer segmentation model** | *I developed a new customer segmentation model with improved performance compared to the existing model. I further supported the data engineering team to continuously deploy new model versions.* | **Machine Learning, Data Preparation, Data Visualization, SPSS Modeler** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Business Deal Completion Rate Optimization** ![abschlussquoten_optimierung](images/projects/abschlussquoten_optimierung.png)| **To increase the completion rate of business deals** | *I developed a classification model based on tabular data providing propensity scores for business deal completion that could be used for priorization purposes. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn), Jupyter** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Price Optimization** ![price_sensitivity](images/projects/price_sensitivity.png)| **To optimize product prices** | *I developed a classification model based on tabular data as a foundation for further product price optimization. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn, spacy), Jupyter, SPSS modeler** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Price Forecasting** ![price](images/projects/price.png)| **To predict electricity market prices** | *I developed a regression model based on historical time-series data to estimate the electricity market price for the next day. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Deep-Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn, keras), Jupyter, VSCode** |
| **Use Case** | **Project Goal** | **my Role** | **Skills & Tools** |
| **Meter Forecasting** ![meter_reading_forecast](images/projects/meter_reading_forecast.png)| **To forecast meter-readings** | *I developed a regression model based on historical time-series data to forecast meter-readings. In addition, I advised the specialist department on the benefits and pitfalls during use of the model.* | **Machine Learning, Deep-Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn, keras), Jupyter, VSCode** |

&nbsp;

# **Academic Research ML-Projects**

| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| ----------- | ----------- | ----------- | ----------- |
| **Medical-Imaging** ![qBOLD_ann](images/projects/qBOLD_ann.png) | **Estimate voxel-wise oxygen extraction fraction (OEF) using an artifical neural network** | *An artificial neural network regression model was developed with the input being the GESSE-BOLD signal and multiple outputs with one being the oxygen extraction fraction, which is an important parameter for tissue vitality. Compared to normal least-squares fitting, the oef-maps were clearly improved. (More details are provided in: Domsch et al., Magnetic Resonance in Medicine, 79(2), pp.890-899, 2018)* | **Magnetic Resonance Imaging, Machine Learning, Artificial Neural Networks, Matlab** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Medical-Imaging** ![diff_ann](images/projects/diff_ann.png) | **Estimate voxel-wise diffusion parameters using an artifical neural network** | *An artificial neural network regression model was developed with the input being diffusion-weighted MR images and with multiple outputs being important diffusion parameters reflecting tissue vitality. Compared to normal least-squares regression fitting, the diffusion parameter maps were clearly improved. (More details are provided in: Domsch et al., NMR Biomed, 30(12), 2017)* | **Magnetic Resonance Imaging, Machine Learning, Artificial Neural Networks, Matlab** |

&nbsp;

## **Personal-Interest ML-Projects**

| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| ----------- | ----------- | ----------- | ----------- |
| **Cardio-Vascular Disease Model** ![cardio_vascular_disease](images/projects/cardio_vascular_disease.png) <small><small>*Image courtesy: guardian.ng*</small> | **Implement and deploy cardiovascular disease model in AWS-Sagemaker** | *I developed a classification model providing disease propensity scores based on labeled data. The proof-of-concept study also included data preparation, data visualization and model performance evaluation and model optimization. The model is deployed as an endpoint in aws-sagemaker. (The code and more details are provided in my github.)* | **Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, sklearn, matplotlib, seaborn, sagemaker, boto3), AWS-Sagemaker** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Topic Modeling API** ![topic_modeling](images/projects/topic_modeling.png) | **Implement and deploy a topic extraction model with flask-api backend** | *I developed a natural language based on the latent-dirichlet-allocation algorithm to extract topics for given articles. The training data contains over 1.000 different english articles covering various topics. Since topic modeling is an unsupervised-learning task, the ground-truth about the actual topics is unknown. However, checking the proposed topics shows high plausibility. Finally I deployed the model using a flask-api backend. (The code and more details are provided in my github.)* | **Natural Language Processing, Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, sklearn, matplotlib, nltk, flask), VSCode, Jupyter Notebook** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Object Detection** ![object_detection](images/projects/object_detection.png) | **Implement object detection model using Azure Cognitive Services** | *I trained a fruit detection model applying Azure´s cognitive services. Training the model was carried out with as little as 33 images showing different fruits. The model´s performance with an overall recall of 93% and precision of 100% was quite astonishing. The reason behind is that a pre-trained model was used. (The code and more details are provided in my github.)* | **Image Processing, Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, sklearn, matplotlib, pil), VSCode, Jupyter Notebook, Azure Cognitive Services** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Text Analysis** ![sentiment](images/projects/sentiment.png) <small><small>*Image courtesy: thedatascientist.com*</small>  | **Implement a language recognition model using Azure Cognitive Services** | *I trained a language recognition model to identify languages, extract keywords and entities and analyse sentiments from hotel reviews using Azure´s cognitive services. I trained a pre-trained language model with as little as five reviews. However, this was sufficient to achieve very good performance. (The code and more details are provided in my github.)* | **Natural Language Processing, Machine Learning, Data Preparation, Python (numpy, pandas, sklearn, matplotlib), VSCode, Jupyter Notebook, Azure Cognitive Services** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Credit Default Prediction App** ![default_pred_app](images/projects/default_pred_app.png) <small><small>*Image courtesy: kindpng.com*</small> | **Implement and deploy a credit default risk model in docker with streamlit for both backend and frontend** | *First, I trained, tuned and evaluated a classification model on public data to predict customers` credit default risks. Then I deployed the final model in docker with streamlit for both backend and frontend. The app allows the user to explore the dataset, train and validate the model and to visualize single model decisions based on shapley values (explainable AI). (The code and more details are provided in my github.)* | **Machine Learning, Data Preparation, Python (numpy, pandas, matplotlib, sklearn, streamlit, docker), VSCode, Jupyter** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Diabetis-Risk Prediction API** ![default_pred_app](images/projects/diabetis_image.png) <small><small>*Image courtesy: aok-erleben.de*</small> | **Implement and deploy a diabetis-risk model in docker with flask-api backend** | *First, I trained a few classification models on public data to predict diabetis risks. Thereby, the model with the best performance was identified applying a custom scoring function in order to meet business requirements (e.g. a false negative prediction leads to higher costs than a false positive prediction). Moreover, aspects of responsible AI such as model explainability and also model fairness were analyzed.  I deployed the final model in docker with a flask-api backend. (The code and more details are provided in my github.)* | **Explainable AI, Fair AI, Machine Learning, Data Preparation, Data Visualization, Python (numpy, pandas, matplotlib, sklearn, shap, fair-learn, docker), VSCode, Jupyter** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Churn Prediction API** ![churn_pred_api](images/projects/churn.png) | **Implement and deploy a churn risk model in docker with fast-api backend using auto-ml** | *First, I trained a few classification models on public data to predict individual churn risks using auto-ml. Thereby, the model with the best performance was identified applying a custom scoring function in order to meet business requirements (e.g. a false negative prediction leads to higher costs than a false positive prediction). Moreover, aspects of responsible AI such as model explainability and also model fairness were analyzed. I deployed the final model in docker with a fast-api backend. (The code and more details are provided in my github.)* | **Automated Machine-Learning, Explainable AI, Fair AI, Data Preparation, Data Visualization, Python (numpy, pandas, pycaret, fastapi, docker), VSCode, Jupyter** |
| **Use Case** | **Project Goal** | **Implementation** | **Skills & Tools** |
| **Customer Lifetime Value Prediction** ![clv](images/projects/customer_value.png) | **Develop responsible AI model (i.e. explainable and fair) to predict lifetime values of bank customers** | *Within a PoC-study I implemented an explainable and fair machine-learning regression model to predict lifetime value scores of bank customers. (The code and more details are provided in my github.)* | **Responsible AI (Explainable AI, Fair AI), Data Preparation, Data Visualization, Machine Learning, Python (numpy, pandas, matplotlib, sklearn, shap, fairlearn), VSCode, Jupyter** |





